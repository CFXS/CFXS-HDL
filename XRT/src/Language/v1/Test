
void Test_v1(const std::string& source, const std::filesystem::path& sourcePath) {
    auto tok = new XRT::Tokenizer;
    try {
        auto tokens = tok->Tokenize(source, &sourcePath);
        // for (const auto& t : tokens) {
        // t->Print();
        // }
        std::string hl = "";
        size_t line    = 1;
        size_t col     = 0;
        for (size_t i = 0; i < source.size(); i++) {
            if (source[i] == '\n') {
                line++;
                col = 0;
                hl += "\n";
                continue;
            } else {
                col++;
            }
            std::string color = ANSI_RESET;

            std::string type = "???";
            for (const auto& t : tokens) {
                if (t->GetLine() == line && col >= t->GetColumn() && col < (t->GetColumn() + t->GetEntrySize())) {
                    switch (t->GetType()) {
                        case XRT::Lexer::TokenType::KEYWORD:
                            type  = "KEYWORD";
                            color = ANSI_BLUE;
                            break;
                        case XRT::Lexer::TokenType::IDENTIFIER: {
                            type     = "IDENTIFIER";
                            auto val = t->GetValue_utf8();
                            if (ctre::match<"bool|unsigned|true|false|unsigned|logic">(val.begin(), val.end())) {
                                color = ANSI_MAGENTA;
                            } else if (ctre::match<"std|range_of|CFXS|EventSource|pow|is_integral|clockable|Event">(val.begin(),
                                                                                                                    val.end())) {
                                color = "\u001b[33m";
                            } else if (ctre::match<"CascadeClockDivider">(val.begin(), val.end())) {
                                color = ANSI_GREEN;
                            } else {
                                color = ANSI_RESET;
                            }
                            break;
                        }
                        // case XRT::Lexer::TokenType::INVALID_IDENTIFIER:
                        //     type  = "INVALID_IDENTIFIER";
                        //     color = ANSI_RED;
                        //     break;
                        case XRT::Lexer::TokenType::LITERAL:
                            type  = "LITERAL";
                            color = ANSI_CYAN;
                            break;
                        // case XRT::Lexer::TokenType::INVALID_LITERAL:
                        //     type  = "INVALID_LITERAL";
                        //     color = ANSI_RED;
                        //     break;
                        case XRT::Lexer::TokenType::OPERATOR:
                            type  = "OPERATOR";
                            color = ANSI_YELLOW;
                            break;
                        case XRT::Lexer::TokenType::PUNCTUATOR:
                            type  = "PUNCTUATOR";
                            color = ANSI_GRAY;
                            break;
                        case XRT::Lexer::TokenType::COMMENT:
                            type  = "COMMENT";
                            color = ANSI_DARK_GREEN;
                            break;
                    }
                    break;
                }
            }

            // hl += color + "[ " + type + " | " + source[i] + " ]\n" + ANSI_RESET;
            hl += color + source[i] + ANSI_RESET;
        }

        LOG_TRACE("\n{}", hl);

    } catch (const XRT::TokenizerException& e) {
        LOG_TRACE(e.GetReason());
    } catch (std::exception* e) {
        LOG_CRITICAL("Tokenize error: {}", e->what());
    }
}